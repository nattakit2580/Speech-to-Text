{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\python312\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\python312\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from SpeechRecognition) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-speech\n",
      "  Using cached google_cloud_speech-2.26.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech)\n",
      "  Using cached google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 (from google-cloud-speech)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\python312\\lib\\site-packages (from google-cloud-speech) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\python312\\lib\\site-packages (from google-cloud-speech) (4.25.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\python312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\python312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.64.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech)\n",
      "  Using cached grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.3.3)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.9)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech)\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.2.2)\n",
      "Using cached google_cloud_speech-2.26.0-py2.py3-none-any.whl (284 kB)\n",
      "Using cached google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: pyasn1-modules, grpcio-status, google-auth, google-api-core, google-cloud-speech\n",
      "Successfully installed google-api-core-2.19.0 google-auth-2.29.0 google-cloud-speech-2.26.0 grpcio-status-1.62.2 pyasn1-modules-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\python312\\lib\\site-packages (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "import pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone Array (Realtek(R) Au',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Primary Sound Capture Driver',\n",
       " 'Microphone Array (Realtek(R) Audio)',\n",
       " 'Primary Sound Driver',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Microphone Array (Realtek(R) Audio)',\n",
       " 'Microphone Array (Realtek HD Audio Mic Array input)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Microphone (Realtek HD Audio Mic input)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<speech_recognition.Microphone at 0x1b6a0387110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the microphone index\n",
    "mic_index = 1  # เปลี่ยนเป็นดัชนีของไมโครโฟนที่คุณต้องการใช้\n",
    "mic = sr.Microphone(device_index=mic_index)\n",
    "mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<speech_recognition.Recognizer at 0x1b6a0189dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recog = sr.Recognizer()\n",
    "recog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ตอบสักคำสั่งอะไรบางอย่างแล้วถ้าเกิด Error เนี่ยให้ทำอีกอย่างนึงครับซึ่งถ้าเขียนแบบนี้ก็คือถ้าสมมุติว่าคำสั่งนี้เกิด Error ปุ๊บให้มันมาที่เอ็กเซฟและทำความสะอาด Continue Continue ก็คือให้มันกลับไปที่ Y ดูดตัวข้างบนครับดังนั้นเนี่ยตัวนี้ก็เกิด Error ปุ๊บมันก็จะไม่แสดง Error แต่ทำงานต่อเลยครับ\n"
     ]
    }
   ],
   "source": [
    "with mic as source:\n",
    "    while True:\n",
    "        audio = recog.listen(source)\n",
    "        print(recog.recognize_google(audio,language='th-TH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาษาอะไรครับวันนี้เราจะให้มันแปลภาษาไทยกันนะครับวิธีการกำหนดก็คือเราจะใช้ Language นะครับต้องกดแถบดูนะครับแล้วก็ใส่ th เข้าไปนะครับเป็น Stick ซึ่งตัวนี้เนี่ยถ้าเกิดเราไม่กำหนดแล้วมันก็จะได้เป็นภาษาอังกฤษตัว default ครับแล้วพอเราให้มันแปลงเสร็จนะครับเราจะให้มันแสดงผลออกมาด้วยนะครับโดยการใช้คำสั่งพื้นตัวนี้เดี๋ยวเรามาดูผลของการแกะเสียงออกมาเป็น text กันครับผมจะลองโทรตัวนี้นะครับ\n",
      "ช่วยหน่อยครับ\n",
      "เป็นไงครับมันก็จะได้มาเลยนะครับถ้าใครชอบคลิปนี้นะครับอย่าลืมกดไลค์กดแชร์กด Subscribe ให้กับ Ultimate ถ่ายตอนด้วยนะครับ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mic \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;28mprint\u001b[39m(recog\u001b[38;5;241m.\u001b[39mrecognize_google(audio,language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth-TH\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mic as source:\n",
    "    while True:\n",
    "        audio = recog.listen(source)\n",
    "        try:\n",
    "            print(recog.recognize_google(audio,language='th-TH'))\n",
    "        except:\n",
    "            continue            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Input', 'Microphone Array (Realtek(R) Au', 'Microsoft Sound Mapper - Output', 'Speakers (Realtek(R) Audio)', 'Primary Sound Capture Driver', 'Microphone Array (Realtek(R) Audio)', 'Primary Sound Driver', 'Speakers (Realtek(R) Audio)', 'Speakers (Realtek(R) Audio)', 'Microphone Array (Realtek(R) Audio)', 'Microphone Array (Realtek HD Audio Mic Array input)', 'Stereo Mix (Realtek HD Audio Stereo input)', 'Speakers (Realtek HD Audio output)', 'Microphone (Realtek HD Audio Mic input)']\n",
      "พูดเลย! กำลังฟัง...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m recog\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)  \u001b[38;5;66;03m# ลดเสียงรบกวนจากสภาพแวดล้อม\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Calculate elapsed time since the start\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:491\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    493\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import speech_recognition as sr\n",
    "\n",
    "# List all microphone names\n",
    "print(sr.Microphone.list_microphone_names())\n",
    "\n",
    "# Specify the microphone index\n",
    "mic_index = 1  # เปลี่ยนเป็นดัชนีของไมโครโฟนที่คุณต้องการใช้\n",
    "\n",
    "# Create a Recognizer instance\n",
    "recog = sr.Recognizer()\n",
    "\n",
    "# Create a Microphone instance\n",
    "mic = sr.Microphone(device_index=mic_index)\n",
    "\n",
    "# Start the initial time\n",
    "initial_time = time.time()\n",
    "\n",
    "# Capture audio from the microphone\n",
    "with mic as source:\n",
    "    print(\"พูดเลย! กำลังฟัง...\")\n",
    "    recog.adjust_for_ambient_noise(source)  # ลดเสียงรบกวนจากสภาพแวดล้อม\n",
    "\n",
    "    while True:\n",
    "        audio = recog.listen(source)\n",
    "        \n",
    "        # Calculate elapsed time since the start\n",
    "        current_time = time.time()\n",
    "        elapsed_time = int(current_time - initial_time)\n",
    "        \n",
    "        # Format elapsed time as minutes:seconds\n",
    "        minutes = elapsed_time // 60\n",
    "        seconds = elapsed_time % 60\n",
    "        time_str = f\"{minutes:02}:{seconds:02}\"\n",
    "        \n",
    "        try:\n",
    "            # Recognize speech using Google Web Speech API\n",
    "            text = recog.recognize_google(audio, language='th-TH')\n",
    "            print(f\"{time_str} {text}\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(f\"{time_str} ไม่สามารถเข้าใจเสียงได้\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"{time_str} เกิดข้อผิดพลาดในบริการการรู้จำเสียง: {e}\")\n",
    "\n",
    "        # Sleep for a short time to allow continuous processing\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Input', 'Microphone Array (Realtek(R) Au', 'Microsoft Sound Mapper - Output', 'Speakers (Realtek(R) Audio)', 'Primary Sound Capture Driver', 'Microphone Array (Realtek(R) Audio)', 'Primary Sound Driver', 'Speakers (Realtek(R) Audio)', 'Speakers (Realtek(R) Audio)', 'Microphone Array (Realtek(R) Audio)', 'Microphone Array (Realtek HD Audio Mic Array input)', 'Stereo Mix (Realtek HD Audio Stereo input)', 'Speakers (Realtek HD Audio output)', 'Microphone (Realtek HD Audio Mic input)']\n",
      "พูดเลย! กำลังฟัง...\n",
      "00:31 เพราะฉะนั้นเราอยากให้มันมาช่วยใน area ที่เราไม่เก่ง AirAsia ที่เรา\n",
      "01:15 มันไม่เหมือนกันบางคนคิดภาพใหญ่ก่อนบางคนคิด Bottom up อะไรเงี้ยเพราะฉะนั้นถ้าคิดแต่ละคนมันไม่เหมือนกันเพราะฉะนั้นมันก็จะพร้อมใครพร้อมมันแต่สุดท้ายพอเวลาผมสอนถ้าเป็นผู้บริหารนะผมบอกว่าพี่ไม่ต้องแคร์หรอกว่าพี่เห็นความดีไม่ดีถ้าพี่ตั้งคำถามเก่งพี่สั่งงานน้องพี่ได้บีบน้องพี่ได้พี่ทำแบบเดียวกันกับชีวิตเริ่มแบบถามง่อยๆก่อนก็ได้เดี๋ยวมันจะตอบไม่ค่อยมาก็ด่ามันกลับไปแล้วเดี๋ยวมันก็จะตอบฉลาดขึ้นแต่ว่ามันขอบคุณด้วยนะบางทีพี่พี่เคยมีมันขอบคุณมันแล้วมันทำดีขึ้นด้วยนะให้มัน\n",
      "01:49 ส่งของจาก routing ยังไงให้ optimize ที่สุดตั้ง Warehouse ตรงไหนที่สุดก็คือเอาคณิตศาสตร์มาแก้ปัญหาธุรกิจเลยก็เลยเริ่มเห็นภาพการเอา Data การเอาไอ้เนี่ย algorithm ต่างๆมาแก้ปัญหาธุรกิจก็เริ่มสนใจตรงนี้มาแล้วก็เรียนจนจบปริญญาโทปริญญาเอกที่ MRT มาแล้วก็เอ้ยคนกำลังพูดถึง Big Data Science พอดีเลย\n",
      "01:59 เปิดความสะดวกทุกคนในองค์กรที่อยากจะใช้ข้อมูลให้ภาค 2 แล้วก็สำคัญมากสำคัญมากสำคัญมากครับเพราะว่าไม่งั้นจะต้อง\n",
      "03:16 หลายๆองค์กรในไทยเนี่ยจริงๆติดกับดักดีคือผมว่าเดี๋ยวถ้าเปิดไปเดี๋ยวคนนั้นเห็นก็อปไปให้คู่แข่งเดี๋ยวคนนั้นเห็นลีกคือมันก็จะมีคอนเสิร์ตที่ค่อนข้างจะต้องทำสตูดิโอหรือเปล่าอ่าเอาจริงๆตอนนั้น EXO ตอนนี้ดีกว่าเรื่อง AI เนาะวันนี้มีดร้ามาทันทีก็ต้องคุยเรื่องนี้ซะหน่อยอันดับแรกคิดว่าวันนี้ที่เราบันทึกวีดีโอนี้เนี่ยนะเพิ่งเปิดตัวเป็น 2,000 บาทส่วนใหญ่มันจะเป็นโรคที่เรียกว่าอะไรที่มันสอนให้เหนื่อยแล้วเหนื่อยเหนื่อยเรื่องถูกแล้วก็ตลกได้นิดนึง\n",
      "04:27 เรื่องแรกเวลาชนองค์กรคุยผมชอบถอยกลับมาก่อนช่วยแยกเว็บปัจจุบันที่เราเรียกจำเป็นว่า generative AI กับเว็บก่อนหน้านี้ทีเมื่อกี้เราบอกหากินใช้ทำโมเดลเพอร์เซอร์ไลฟ์ส่วนใหญ่มันจะเป็นโรคที่เรียกว่าทีม AI อยากให้แยกสารแยกออกจากกันก่อนนะครับ AI จะยังมีอยู่และจะยังมีต่อไปโดยเฉพาะอย่างยิ่งข้อมูลที่มันเป็นตัวเลขเป็นตารางเนี่ยเอามาคำนวณหาคนที่ชอบอะไรเหมือนๆกันนู่นนี่นั่นคือ AI เก่งกว่ามากแล้วก็ตรงนี้ก็จะยังคงอ่าแต่ถ้าเป็น Research ของแมคเคนซีเลยเนี่ยจริงๆก็ 4 ตัวเลขมาเขาบอกว่าอยู่ของก็ยังมากกว่า Agency AI ประมาณ 1 แต่ผมว่าตอนนี้มันน่าจะเริ่มเปลี่ยนแล้วล่ะเพราะว่า Power ขึ้นมานะครับแต่ว่า Big C AI เป็นก้อนหนึ่งที่ที่อย่าเพิ่งทิ้งมันมันจะยัง\n",
      "04:50 ยังมีที่ยืนของมันและยังมีมูลค่าทางธุรกิจสูงมากนะครับฉะนั้นวิธี AI คือของใหม่ที่จะเข้ามาไอ้ของใหม่ที่เข้ามาเนี่ยตอนนี้ผมว่าขอ 2 แอเรียใหญ่ๆแล้วกัน area แรกคือเพิ่ม productivity ผมว่าอันนี้คือสิ่งที่ทุกคนตื่นเต้นที่สุดเพราะว่า\n",
      "05:01 จ่ายอะไรนะถ้า gpt เดือนนึงไม่ถึง 1,000 บาท\n",
      "06:42 หลายคนก็จะเริ่มรู้สึกว่ามันเก่งกว่าไอ้น้องที่เราใช้งานหลายคนอยู่นะเก่งจริงคือคนที่เก่งกว่าคนไทยคนไทยคนไทยเราใช้ยังเครียดเลยแล้วมันก็ไม่เถียงไม่บ่นไม่อะไรด้วยเพราะฉะนั้นจริงๆเรื่องเอามาช่วยใช้งานเนี่ยผมว่าเป็นเป็น area ใหญ่ใหญ่มากฝากไว้ก่อนกลับกลายเป็นที่ 2 คือเอามาสร้าง innovation แล้วสร้างเป็น product ใหม่ service ใหม่ที่ Advice ให้กับลูกค้ามากขึ้นผมว่าองค์กรถ้าเป็นผู้บริหารเลยน่าจะพยายามมองไอ้ก้อนแอดไดร์เวอร์จะไปยังไงถ้าเอาตัวอย่างล่าสุดก็ได้ Open AI เปิดตัวมาเนาะอันนี้โหดจริงแบบนั่งคุยกันเหมือนเป็นวันๆติวเตอร์ดังนั้นคำถามคือ Education ในอนาคตหน้าตาเป็นยังไงซึ่งถ้ามองแง่ร้ายนะแต่ติวเตอร์หมดแล้วจบเจ๋งเลิกการปิดโรงเรียนปิดมหาลัยกันเถอะแต่ทั้งหมด\n",
      "08:53 โคตรชอบเลย MRT ทำคอร์สมี quotation ออกมาวิชาถ้าใครเคยเรียนตอนเรียนแอมเวย์อยากให้โรงเรียนออฟไลน์ออฟชั่นมันคือแบบมันต้องเถียงแข่งกับเพื่อนใครเถียงชนะกว่ากันแล้วมันดีๆว่าทำไมเมื่อกี้เสียงแท้เมื่อกี้ทำไมถึงไม่สามารถเห็นมุมนั้นมุมนี้ได้แต่วันนี้พอมีไอ้นี่ปุ๊บเขาเอาไอ้นี่ไปทำเป็นโรงเรียน gpp 1 ตัวมาเป็นเป็น expert ในด้านการเจรจาต่อรองแล้วก็ให้เรารู้สึกเจรจาต่อรองกับเขาแล้วก็ดีขึ้นอย่างเงี้ยคือมันก็เอาไปเติมตรงนั้นได้เหมือนกันเพราะฉะนั้นไอ้มุมนึงที่ธุรกิจต้องคิดเลยตอนนี้ Marketing หน่อยนึงแล้วกันผมว่าตอนนี้ทุกคนเห็นละเห็นรูปเป็นเสียง General Mission To the Moon ออกมารวมมากคำถามคือเฮ้ยตกลงต่อไปนี้แบรนด์จะทำ 8 จะทำสื่อเราจะต้องเช่าสตูดิโอใหญ่ๆบ้างแต่ยังต้องจ้างนักร้องดาราแพงๆหรือเปล่าหรือไม่จำเป็นที่เหมาะพวกนี้มันก็จะเปลี่ยนวิธีคิดเปลี่ยนการเรียกว่าแปรยูเครนในหลายๆธุรกิจมันจะเริ่มคิดไปอันนี้เป็นอันที่ผมว่าผู้บริหารส่วนเรื่องเพิ่มระดับผมว่าจริงๆตรงไปตรงมาส่วนตัวผมมองว่าเป็นเว็บมีอยู่ยุคหนึ่งพวกเรามาหัดใช้เครื่องคิดเลขแล้วก็มีเว็บนึงของเราอาจใช้ Excel Excel กลายเป็นเครื่องมือมาตรฐานทุกคนใช้เป็นคือผมว่าไอ้โค Pilot ต่างๆมันก็กำลังจะเข้าอีหรอบนั่นแหละเข้ามาช่วยพวกเราทำงานนู่นนี่นั่นได้มากขึ้นนะครับเพียงแต่ว่าก็อยากให้ใช้เป็น agenda นิดนึงเพราะว่าคนใช้ไม่เป็นคนใช้เป็นภาษากันเยอะ\n",
      "11:39 เปิดตัวของตัวเองอยู่ใน workspace Microsoft ว่าอินทิเกรตโคไพลอตเข้าไปในทุกอย่างของใครของมันแล้วพอไม่มีใครอยากจะมีครูเต็มเครื่องไปหมดแล้วไม่ต้องเลือกลายมันต้องเลือกครับผมก็ถ้าถามผมพรุ่งนี้จริงๆถ้าเป็นมุมผู้บริหารแล้วกันผมก็จะบอกว่าเน้นเตรียมคนให้พร้อมคือไม้เครื่องมือไม่ต้องห่วงมากเพราะว่าบริษัทพวกนี้อยากหาเงินออนไลน์เดี๋ยวเขาก็จะคือตอนนี้หลายคนจะกลัวเรื่อง Security privacy อะไรอย่างเงี้ยของข้อมูลของเราเขาบอกว่าเขารู้อยู่แล้วว่าคุณอยากใช้ในองค์กรอย่างเซอร์ไพรส์เวอร์ชั่นเดี๋ยวเขาก็ออกแต่ไม่ต้องไม่ต้องกลัวนะเตรียมเงินรอไว้เตรียมเงินเตรียมคนรอไว้อ่ะเดี๋ยวเค้าเอาของมาขายเราเองนะครับเพราะฉะนั้นไอ้มุมนี้ผมว่าไม่ค่อยไม่ค่อยน่ากลัวก็แค่เตรียมแล้วก็เตรียมคนขึ้นมาแต่ถ้าจะหน้าโหดอีกนิดนึงนะผมพบว่าอย่างพี่แทบเป็นผู้บริหาร 1 คนที่ใช้แทนที่ทำงานทุกอย่างในโลกนี้ถูกไหมแต่มันจะมีหลายคนที่เหมือน First impression มันไม่ดีเหมือนเขาไปลองใช้การคุยกันไหนเป็นลองซิแล้วก็ลองถามคำถามง่ายๆหรือเขียนเพราะสั้นๆแล้วเราก็จะรู้สึกว่ามันไม่ฉลาดจริงๆเลยแล้วหลายครั้งคือผมว่าเราไปอยู่กับมันกับเราเองเช่นไปลองถามที่ธุรกิจหน่อยมันไม่ทันคิดเกี่ยวกับพี่หรอกถ้าพี่อยู่ใน Industry นี้มา 30 ปีมันก็จะคิดอะไรมาคล้ายๆพี่แล้วเราก็จะรู้สึกว่ามันไม่เก่งขนาดนั้นเรายังเก่งกว่าคือผมว่าถ้าเราไปตัดสินมันด้วยมุมนั้นน่ะเราจะไม่เห็นประโยชน์เลยแล้วมันก็จะมีครึ่งนึงของของผู้บริหารที่อาจจะยังครึ่งๆกับเทคโนโลยีนี้แฟชั่นหรือเปล่ามันแทนคนจริงๆไม่ได้หรอกมันยังห่างไกลอันนี้ผมก็อาจจะชวนว่าถ้าใครยังรู้สึกว่าอยู่ในค่ายนี้ต้องใช้เยอะๆครับคือคนเก่งมากๆทุกคนที่ผมรู้จักใช้แล้วแล้วทุกคนก็จะยังบอกว่ามันดีกว่าที่เราคิดจริงๆคือมันช่วยเราได้เยอะแบบมหาศาลเพราะฉะนั้นถ้าใครที่ยังรู้สึกว่ามันไม่ค่อยมีประโยชน์หรือว่าใช้มันเต็มศักยภาพทุกอย่างแล้ว\n",
      "14:54 ดีที่สุดแล้วก็เป็นมุมที่คนอื่นต้องไปกินข้าวกับพี่ต้องกวีวุฒิมาพี่ต้องดีไซน์ Thinking เขาบอกใช่เลยแต่ดีไซน์จริงๆสิ่งที่เราคุยกันคืออยากได้ดีที่ดีเนี่ยต้องได้ไอเดียเยอะๆซึ่งอยากได้เนื้อเยอะเนี่ยมันต้องแยกกันเจนเนอเรทกับการ evaluate หรือการเลือกไอเดียซึ่งมนุษย์เนี่ย generate ไอเดียไม่เก่งเค้าห้องประชุมไปเนี่ยบอกผู้บริหารขอ 50 ไอเดียอึ้งทั้งห้องอ่ะมันจะแบบมันจะฝืดมากมันจะออกมาทีละอันแต่ 50 ไอเดียใช้ gpt ขอ 5 วิออกมาจบแต่มนุษย์เก่งอะไรรถแข่งเลือกครับเราปิดได้ทุกอย่างในโลกนี้ไอเดียนี้ไม่ดีเพราะอะไรมันน่าจะต้องปรับอย่างนี้เฮ้ยโอเคพอไปได้ต่อยอดแต่เราก็จะไปต่อยอดได้เพราะฉะนั้นอย่ายุ่งมหาศาลคิดไม่ออกช่วยคิดให้หน่อยอันนี้จริงๆแต่คิดมาเสร็จไอ้เรื่องๆเนี่ยฉันเก่งกว่าฉันจะเข้าจริงๆดีกว่าอยู่แน่นอนแต่จะเลือกเองว่าอันไหนดีเช่นจะคิดสโลแกนเอามาเลยสัก 500 คนแก่ก็ทำได้นะครับผมบอกทุกคนว่าหลังจากใช้ gpt ออกมาเนี่ยชื่อ Talk ชื่องานไทยเท่าไรบอกว่าดีหมดเพราะว่าขายแล้วเป็นหลายสิบหลายร้อยเลย\n",
      "16:31 มันจะกลับมาสำคัญมากผมว่าสำคัญเป็นผู้ได้ 2 กลุ่มแล้วกัน 1 คือจะบอกว่าน้อยก็ได้เพราะไอ้โมเดลพวกนี้ผมเชื่อว่าอีกไม่นานภาษาไทยมันจะเริ่มแคทอัพแล้วเราก็จะทำทุกอย่างเป็นภาษาไทยได้แต่ถ้าจะบอกว่ามากขึ้นอีกผมว่ามันก็มากขึ้นอีกเพราะถ้าใครใช้ภาษาอังกฤษคล่องตอนนี้คุณวิ่งนำไปแล้วอ่ะแล้วก็ต้องบอกว่าถ้าใครลองใช้ก็จะรู้ว่าเวลาสั่งมันเป็นภาษาอังกฤษจึงจะรอมันคิดเก่งกว่าเป็นภาษาไทยเพราะว่ามันเชื่อมโยงกับคำภาษาอังกฤษด้วยกันด้วยบริบทเท่าที่มันมีอะไรอย่างเงี้ยจริงๆมันทำได้เก่งกว่าทำได้ดีกว่าแล้วก็ถ้าเอา Technical กว่านั้นก็คือทำได้เอฟเฟคเสียงมากกว่าจำนวน Token ที่ใช้อะไรอย่างเงี้ยภาษาไทยมันมันไม่ได้เกิดมาเพื่อ Perfect กับไอ้โมเดลพวกนี้แต่แรกแล้วคนใช้ภาษาอังกฤษก็เยอะกว่าเยอะมีอะไรอยู่อยู่ตรงนั้นที่ค่อนข้างเยอะเพราะฉะนั้นผมผมมองในมุมว่าทุกอย่างมันจะถูกเร่งแต่ก่อนเนี่ยความรู้ใหม่มามีคนแปลงเหมือนซื้อใหม่ๆมาเนี่ยมีคนตายในหนังสือและคนไทยตรงนั้นแต่ว่าตอนนี้พอเราบอกเราอยู่ในโลกที่แบบภายใน 2 ปี AI เปลี่ยนขนาดนี้แล้วเราจะรอแต่คนนี้ออกเทคนิคคนนี้แปลมันไม่ทันจริงอ่ะ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m         text \u001b[38;5;241m=\u001b[39m recog\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth-TH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Calculate elapsed time since the start\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import speech_recognition as sr\n",
    "\n",
    "# List all microphone names\n",
    "print(sr.Microphone.list_microphone_names())\n",
    "\n",
    "# Specify the microphone index\n",
    "mic_index = 1  # เปลี่ยนเป็นดัชนีของไมโครโฟนที่คุณต้องการใช้\n",
    "\n",
    "# Create a Recognizer instance\n",
    "recog = sr.Recognizer()\n",
    "\n",
    "# Create a Microphone instance\n",
    "mic = sr.Microphone(device_index=mic_index)\n",
    "\n",
    "# Start the initial time\n",
    "initial_time = time.time()\n",
    "\n",
    "# Capture audio from the microphone\n",
    "with mic as source:\n",
    "    print(\"พูดเลย! กำลังฟัง...\")\n",
    "    recog.adjust_for_ambient_noise(source)  # ลดเสียงรบกวนจากสภาพแวดล้อม\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            audio = recog.listen(source)\n",
    "            text = recog.recognize_google(audio, language='th-TH')\n",
    "            \n",
    "            # Calculate elapsed time since the start\n",
    "            current_time = time.time()\n",
    "            elapsed_time = int(current_time - initial_time)\n",
    "            \n",
    "            # Format elapsed time as minutes:seconds\n",
    "            minutes = elapsed_time // 60\n",
    "            seconds = elapsed_time % 60\n",
    "            time_str = f\"{minutes:02}:{seconds:02}\"\n",
    "            \n",
    "            print(f\"{time_str} {text}\")\n",
    "            \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"ไม่สามารถเข้าใจเสียงได้\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"เกิดข้อผิดพลาดในบริการการรู้จำเสียง: {e}\")\n",
    "        \n",
    "        # Optional: Sleep for a short time to avoid high CPU usage\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พูดเลย! กำลังฟัง...\n",
      "กำลังถอดเสียง...\n",
      "คุณพูดว่า: นะครับเราจะมาเรียนรู้กับหมวดของคณิตศาสตร์ในปัญญาประดิษฐ์เนื่องจากในปัจจุบันนะครับ AI นะเนี่ยสำคัญกับชีวิตของเรามากเราจึงต้องเรียนรู้และพัฒนาฝึกฝนตัวเอง\n"
     ]
    }
   ],
   "source": [
    "# Capture audio from the microphone\n",
    "with mic as source:\n",
    "    print(\"พูดเลย! กำลังฟัง...\")\n",
    "    recog.adjust_for_ambient_noise(source)  # ลดเสียงรบกวนจากสภาพแวดล้อม\n",
    "    audio = recog.listen(source)\n",
    "\n",
    "try:\n",
    "    # Recognize speech using Google Web Speech API\n",
    "    print(\"กำลังถอดเสียง...\")\n",
    "    text = recog.recognize_google(audio, language='th-TH')\n",
    "    print(\"คุณพูดว่า: \" + text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"ไม่สามารถเข้าใจเสียงได้\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"เกิดข้อผิดพลาดในบริการการรู้จำเสียง: {0}\".format(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
